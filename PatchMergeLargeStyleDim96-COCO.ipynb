{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fee0a0ea-0c2d-4f1c-a00a-fd5f656d3bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c6dbe47-85fa-480d-970a-f4101ae2e2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()\n",
    "# Set the default dtype to float64 (double precision)\n",
    "# torch.set_default_dtype(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ef3ed1e-e2ff-4915-a093-5f30287afdc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è no model scale passed. Assuming scale='s'.\n",
      "True\n",
      "[384, 384, 384, 384]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming the YAML configuration is saved in \"custom_yolo.yaml\"\n",
    "model = YOLO(\"/home/ubuntu/yamls/640-base384.yaml\")\n",
    "# # model = model.to(torch.bfloat16)     # Convert to bfloat16\n",
    "# model.model = torch.compile(model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d960e8b5-eb70-441d-ba44-4654119a38f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add the callback\n",
    "# def enable_anomaly_detection(trainer):\n",
    "#     torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# model.add_callback(\"on_pretrain_routine_start\", enable_anomaly_detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56df9fc9-2efd-4d4a-82df-2f2b6255cdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch import nn\n",
    "\n",
    "# # Forward hook function to check for NaN in outputs\n",
    "# def nan_hook(module, input, output):\n",
    "#     if not isinstance(output, tuple):\n",
    "#         outputs = [output]\n",
    "#     else:\n",
    "#         outputs = output\n",
    "#     for i, out in enumerate(outputs):\n",
    "#         if out is not None and torch.isnan(out).any():\n",
    "#             print(f\"NaN found in output {i} of {module}\")\n",
    "\n",
    "# # Backward hook function to check for NaN in gradients\n",
    "# .\n",
    "# def nan_backward_hook(module, grad_input, grad_output):\n",
    "#     if grad_input is not None:\n",
    "#         if not isinstance(grad_input, tuple):\n",
    "#             grad_inputs = [grad_input]\n",
    "#         else:\n",
    "#             grad_inputs = grad_input\n",
    "#         for i, gi in enumerate(grad_inputs):\n",
    "#             if gi is not None and torch.isnan(gi).any():\n",
    "#                 print(f\"NaN found in grad_input {i} of {module}\")\n",
    "#     if grad_output is not None:\n",
    "#         if not isinstance(grad_output, tuple):\n",
    "#             grad_outputs = [grad_output]\n",
    "#         else:\n",
    "#             grad_outputs = grad_output\n",
    "#         for i, go in enumerate(grad_outputs):\n",
    "#             if go is not None and torch.isnan(go).any():\n",
    "#                 print(f\"NaN found in grad_output {i} of {module}\")\n",
    "\n",
    "# # Function to register hooks on all modules in the model\n",
    "# def register_nan_hooks(model):\n",
    "#     for name, module in model.named_modules():\n",
    "#         module.register_forward_hook(nan_hook)\n",
    "#         module.register_full_backward_hook(nan_backward_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7ff4ede-2f38-4226-bec2-501d956e6fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch import nn\n",
    "\n",
    "# # Forward hook function to check for NaN in outputs\n",
    "# def nan_hook(module, input, output):\n",
    "#     if not isinstance(output, tuple):\n",
    "#         outputs = [output]\n",
    "#     else:\n",
    "#         outputs = output\n",
    "#     for i, out in enumerate(outputs):\n",
    "#         if out is not None and torch.isnan(out).any():\n",
    "#             print(f\"NaN found in output {i} of {module}\")\n",
    "\n",
    "# # Backward hook function to check for NaN in gradients\n",
    "# def nan_backward_hook(module, grad_input, grad_output):\n",
    "#     if grad_input is not None:\n",
    "#         if not isinstance(grad_input, tuple):\n",
    "#             grad_inputs = [grad_input]\n",
    "#         else:\n",
    "#             grad_inputs = grad_input\n",
    "#         for i, gi in enumerate(grad_inputs):\n",
    "#             if gi is not None and torch.isnan(gi).any():\n",
    "#                 print(f\"NaN found in grad_input {i} of {module}\")\n",
    "#     if grad_output is not None:\n",
    "#         if not isinstance(grad_output, tuple):\n",
    "#             grad_outputs = [grad_output]\n",
    "#         else:\n",
    "#             grad_outputs = grad_output\n",
    "#         for i, go in enumerate(grad_outputs):\n",
    "#             if go is not None and torch.isnan(go).any():\n",
    "#                 print(f\"NaN found in grad_output {i} of {module}\")\n",
    "\n",
    "# # Function to register hooks on all modules in the model\n",
    "# def register_nan_hooks(model):\n",
    "#     for name, module in model.named_modules():\n",
    "#         module.register_forward_hook(nan_hook)\n",
    "#         module.register_full_backward_hook(nan_backward_hook)\n",
    "\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# # def set_silu_inplace_false(trainer):\n",
    "# #     \"\"\"Set inplace=False for all SiLU activations in the model that have inplace=True.\"\"\"\n",
    "# #     count = 0\n",
    "# #     for module in trainer.model.modules():\n",
    "# #         if isinstance(module, nn.SiLU) and module.inplace:\n",
    "# #             module.inplace = True\n",
    "# #             count += 1\n",
    "# #     print(f\"Set inplace=False for {count} SiLU modules.\")\n",
    "\n",
    "# def register_nan_hooks(trainer):\n",
    "#     \"\"\"Register forward hooks to detect NaN values in module outputs.\"\"\"\n",
    "#     def create_nan_hook(name):\n",
    "#         def nan_hook(module, input, output):\n",
    "#             def check_output(out, path=\"\"):\n",
    "#                 if isinstance(out, torch.Tensor):\n",
    "#                     if torch.isnan(out).any():\n",
    "#                         print(f\"NaN detected at {path} in module '{name}'\")\n",
    "#                 elif isinstance(out, (tuple, list)):\n",
    "#                     for i, elem in enumerate(out):\n",
    "#                         check_output(elem, path + f\"[{i}]\")\n",
    "#                 # Optionally handle other types or None silently\n",
    "#             check_output(output)\n",
    "#         return nan_hook\n",
    "\n",
    "#     for name, module in trainer.model.named_modules():\n",
    "#         if not isinstance(module, nn.SiLU):\n",
    "#             module.register_forward_hook(create_nan_hook(name))\n",
    "#     print(\"Registered NaN detection hooks.\")\n",
    "\n",
    "# # Add callbacks\n",
    "# # model.add_callback('on_train_start', set_silu_inplace_false)\n",
    "# model.add_callback('on_train_start', register_nan_hooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb78039-0549-46b9-bae2-f83a4a9049fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.151 available üòÉ Update with 'pip install -U ultralytics'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.85 üöÄ Python-3.11.12 torch-2.8.0.dev20250518+cu128 CUDA:0 (NVIDIA GH200 480GB, 96768MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/home/ubuntu/yamls/640-base384.yaml, data=coco.yaml, epochs=600, time=None, patience=50, batch=32, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train45, exist_ok=False, pretrained=False, optimizer=auto, verbose=True, seed=0, deterministic=False, single_cls=False, rect=False, cos_lr=True, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=128, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=10, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train45\n",
      "WARNING ‚ö†Ô∏è no model scale passed. Assuming scale='s'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1     74112  ultralytics.nn.modules.block.VitPatchEmbedBlock[3, 384, [640, 640], [8, 8]]  \n",
      "True\n",
      "  1                  -1  1   2457600  ultralytics.nn.modules.block.VitPosEmbedBlock[384, 384, [80, 80]]          \n",
      "  2                  -1  1   7758616  ultralytics.nn.modules.block.ViLBlockPairBlock[384, 384, {'seqlens': [80, 80], 'chunk_size': 512, 'conv_kind': '2d', 'qkv_block_size': 128}]\n",
      "  3                  -1  1    615168  ultralytics.nn.modules.block.PatchMerger     [384, 1600]                   \n",
      "  4                  -1  1   7758616  ultralytics.nn.modules.block.ViLBlockPairBlock[384, 384, {'seqlens': [40, 40], 'chunk_size': 512, 'conv_kind': '2d', 'qkv_block_size': 128}]\n",
      "  5                  -1  1    154368  ultralytics.nn.modules.block.PatchMerger     [384, 400]                    \n",
      "  6                  -1  1   7758616  ultralytics.nn.modules.block.ViLBlockPairBlock[384, 384, {'seqlens': [20, 20], 'chunk_size': 256, 'conv_kind': '2d', 'qkv_block_size': 128}]\n",
      "  7                  -1  1     39168  ultralytics.nn.modules.block.PatchMerger     [384, 100]                    \n",
      "  8                  -1  1   7758616  ultralytics.nn.modules.block.ViLBlockPairBlock[384, 384, {'seqlens': [10, 10], 'chunk_size': 64, 'conv_kind': '2d', 'qkv_block_size': 128}]\n",
      "  9                   2  1         0  ultralytics.nn.modules.block.SequenceToImage [[80, 80]]                    \n",
      " 10                   4  1         0  ultralytics.nn.modules.block.SequenceToImage [[40, 40]]                    \n",
      " 11                   6  1         0  ultralytics.nn.modules.block.SequenceToImage [[20, 20]]                    \n",
      " 12                   8  1         0  ultralytics.nn.modules.block.SequenceToImage [[10, 10]]                    \n",
      " 13                  12  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14            [13, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1   9548056  ultralytics.nn.modules.block.ViLFusionBlock  [768, 384, {'seqlens': [20, 20], 'chunk_size': 256, 'conv_kind': '2d', 'mlp_ratio': 4.0, 'qkv_block_size': 128}]\n",
      " 16                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 17            [16, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1   9548056  ultralytics.nn.modules.block.ViLFusionBlock  [768, 384, {'seqlens': [40, 40], 'chunk_size': 512, 'conv_kind': '2d', 'mlp_ratio': 4.0, 'qkv_block_size': 128}]\n",
      " 19                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 20             [19, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   9548056  ultralytics.nn.modules.block.ViLFusionBlock  [768, 384, {'seqlens': [80, 80], 'chunk_size': 512, 'conv_kind': '2d', 'mlp_ratio': 4.0, 'qkv_block_size': 128}]\n",
      " 22                  21  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 23            [22, 18]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 24                  -1  1   9548056  ultralytics.nn.modules.block.ViLFusionBlock  [768, 384, {'seqlens': [40, 40], 'chunk_size': 512, 'conv_kind': '2d', 'mlp_ratio': 4.0, 'qkv_block_size': 128}]\n",
      " 25                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 26            [25, 15]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 27                  -1  1   9548056  ultralytics.nn.modules.block.ViLFusionBlock  [768, 384, {'seqlens': [20, 20], 'chunk_size': 256, 'conv_kind': '2d', 'mlp_ratio': 4.0, 'qkv_block_size': 128}]\n",
      " 28                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 29            [28, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 30                  -1  1   9548056  ultralytics.nn.modules.block.ViLFusionBlock  [768, 384, {'seqlens': [10, 10], 'chunk_size': 64, 'conv_kind': '2d', 'mlp_ratio': 4.0, 'qkv_block_size': 128}]\n",
      "[384, 384, 384, 384]\n",
      " 31    [21, 24, 27, 30]  1   6056080  ultralytics.nn.modules.head.v10Detect        [80, [384, 384, 384, 384]]    \n",
      "640-base384 summary: 602 layers, 101,702,912 parameters, 101,702,896 gradients, 363.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mTensorBoard logging to runs/detect/train45\n",
      "Freezing layer 'model.31.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/ubuntu/datasets/coco/labels/train2017.cache... 117266 images, 1021 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 118287/118287 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/ubuntu/datasets/coco/labels/val2017.cache... 4952 images, 48 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train45/labels.jpg... \n",
      "auto\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 158 weight(decay=0.0), 295 weight(decay=0.0005), 305 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mgraph failure at 76:4:\n",
      "            # load vecN\n",
      "            # each thread block loads a (siz_b_DHQK,) chunk from vecN_initial\n",
      "            vecNinitial_ptr = (\n",
      "                vecN_initial\n",
      "                + idx_b_BNH * str_vecNinitial_B_NH\n",
      "                + idx_b_DHQK * siz_b_DHQK\n",
      "                + tl.arange(0, siz_b_DHQK)\n",
      "            )\n",
      "            vecN_k_val = tl.load(vecNinitial_ptr).to(tl.float32)\n",
      "\n",
      "    # iterate over chunks\n",
      "    for k in range(NC):\n",
      "    ^\n",
      "TypeError(\"cannot convert 100 of type <class 'torch.Tensor'> to tensor\")\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train45\u001b[0m\n",
      "Starting training for 600 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/600      73.1G      5.451      11.16      6.123        216        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3697/3697 [42:50<00:00,  1.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:41<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5000      36335      0.006     0.0319    0.00506    0.00226\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/600      76.8G      4.115      8.182      4.136        196        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3697/3697 [41:43<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:32<00:00,  4.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5000      36335      0.282     0.0516     0.0342     0.0179\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/600      77.4G      3.651      6.591       3.52        207        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3697/3697 [41:20<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:32<00:00,  4.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5000      36335      0.254      0.144        0.1     0.0582\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/600      78.5G      3.382      5.607      3.204        181        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3697/3697 [41:11<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:32<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5000      36335      0.312      0.215      0.181      0.111\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/600      77.7G       3.18       4.97      2.997        244        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3697/3697 [41:13<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:32<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5000      36335      0.378      0.268      0.247      0.158\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/600      76.5G      3.053      4.582       2.87        171        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3697/3697 [41:14<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:32<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5000      36335      0.449      0.302      0.297      0.193\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/600      77.7G      2.961       4.31      2.785        247        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3697/3697 [41:07<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:32<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5000      36335      0.465       0.33      0.335      0.222\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/600      77.3G      2.892      4.099       2.72        136        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3697/3697 [41:13<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:32<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5000      36335       0.49      0.352      0.364      0.243\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/600      77.3G      2.839      3.943      2.673        184        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3697/3697 [41:13<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:32<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5000      36335      0.505      0.375       0.39      0.264\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/600      76.6G      2.791      3.811      2.628        270        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3697/3697 [41:14<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:32<00:00,  4.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5000      36335      0.529      0.394       0.41       0.28\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/600      76.9G       2.75      3.702      2.595        171        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3697/3697 [41:08<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:32<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5000      36335      0.555      0.401      0.427      0.294\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/600      78.3G      2.716      3.608      2.562        240        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3697/3697 [41:13<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:32<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5000      36335      0.547       0.42      0.442      0.305\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/600      77.5G      2.687      3.524      2.537        136        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3697/3697 [41:13<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:32<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5000      36335      0.559      0.427      0.455      0.315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/600      76.6G      2.661      3.465      2.514        190        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3697/3697 [41:14<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:32<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5000      36335      0.583      0.428      0.463      0.322\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/600      77.4G       2.64      3.407      2.496        171        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3697/3697 [41:06<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:32<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5000      36335      0.576      0.438       0.47      0.329\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/600      77.4G      2.621      3.357      2.479        195        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3697/3697 [41:16<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:32<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5000      36335      0.583       0.44      0.476      0.333\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/600      78.3G      2.601      3.305      2.464        220        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3697/3697 [41:14<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:32<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5000      36335      0.579      0.448      0.481      0.338\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/600      76.9G      2.585      3.262       2.45        227        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3697/3697 [41:13<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:32<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5000      36335      0.582      0.451      0.485      0.341\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/600      77.5G      2.569      3.225      2.438        183        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3697/3697 [41:08<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:32<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5000      36335      0.588      0.452      0.489      0.344\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/600      77.4G      2.558      3.191      2.428        240        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3697/3697 [41:14<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:32<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5000      36335      0.584      0.457      0.493      0.347\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/600      77.5G      2.545      3.149      2.416        353        640:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 2228/3697 [24:51<15:48,  1.55it/s]"
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    data='coco.yaml',\n",
    "    epochs=600,\n",
    "    cos_lr=True,\n",
    "    device=\"0\",\n",
    "    batch=32,\n",
    "    nbs=128,\n",
    "    lr0=1e-3,\n",
    "    lrf=0.01,\n",
    "    workers=8,\n",
    "    optimizer='auto',\n",
    "    imgsz=640,\n",
    "    plots=True,\n",
    "    val=True,\n",
    "    pretrained=False,\n",
    "    visualize=False,\n",
    "    deterministic=False,\n",
    "    augment=True,\n",
    "    amp=True,\n",
    "    warmup_epochs=3,\n",
    "    mosaic=1.0,     # Disable mosaic, unlike YOLO defaults\n",
    "    mixup=0.0,      # Explicitly disable mixup (default is 0.0)\n",
    "    fliplr=0.5,    # Random horizontal flip with 50% probability (default)\n",
    "    hsv_h=0.015,   # Hue adjustment (default)\n",
    "    hsv_s=0.7,     # Saturation adjustment (default)\n",
    "    hsv_v=0.4,     # Value adjustment (default)\n",
    "    degrees=10,   # No rotation (default)\n",
    "    translate=0.1, # 10% translation (default)\n",
    "    scale=0.5,     # 50% scaling (default)\n",
    "    shear=0.0,      # No shearing (default)lr0 = 1e-5                  # Initial learning rate\n",
    "    patience=50,\n",
    "    rect=False,\n",
    "    resume=False,\n",
    "    close_mosaic=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52313420-1284-471a-af54-dca486e01aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in model.model.named_modules():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18603b6-1822-4c0b-a46c-7f6ea4d86c68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
